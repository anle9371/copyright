{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import google.datalab.storage as storage\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def limit(a, b):\n",
    "    if a < b:\n",
    "        return a\n",
    "    else: return b\n",
    "    \n",
    "def generate_cut(image_matrix):\n",
    "    x,y = image_matrix.shape[:2]\n",
    "    x_start = random.randint(0, int(x/2))\n",
    "    y_start = random.randint(0, int(y/2))\n",
    "    x_end = limit(x_start + int(x/2) + random.randint(0, int(x/16)), x)\n",
    "    y_end = limit(y_start + int(y/2) + random.randint(0, int(y/16)), y)\n",
    "    image_cut = image_matrix[x_start:x_end, y_start:y_end]\n",
    "    return image_cut\n",
    "\n",
    "def one_hot(x, len_ls):\n",
    "    a = np.zeros(len_ls, 'int32')\n",
    "    a[x] = 1\n",
    "    return a\n",
    "\n",
    "def gen_file_dict(bucket):\n",
    "  dict_classes = {}\n",
    "  my_keys = [_object.key for _object in bucket.objects() if \".jpg\" in _object.key]\n",
    "  not_sources = [not_source for not_source in my_keys if \"not_sources\" in not_source]\n",
    "  len_encoding = len(my_keys) - len(not_sources) + 1\n",
    "  encoding_pos = 0\n",
    "  \n",
    "  for key in my_keys:\n",
    "    if key in not_sources:\n",
    "      dict_classes[key] = one_hot(len_encoding - 1, len_encoding)\n",
    "    else:\n",
    "      dict_classes[key] = one_hot(encoding_pos, len_encoding)\n",
    "      encoding_pos = encoding_pos + 1\n",
    "  return dict_classes\n",
    "\n",
    "sample_bucket = storage.Bucket(\"copyright\")\n",
    "my_dict = gen_file_dict(sample_bucket)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_image_class_dict(my_dict):\n",
    "  '''this function creates a lookup file that maps an image class to an image. this is used in the demo notebook for presentation.'''\n",
    "  imagedict = {}\n",
    "\n",
    "  for key, value in my_dict.items():\n",
    "    itemindex = np.where(value==1)[0].item(0)\n",
    "    imagedict[itemindex] = []\n",
    "\n",
    "  for key, value in my_dict.items():\n",
    "    itemindex = np.where(value==1)[0].item(0)\n",
    "    imagedict[itemindex].append(key)\n",
    "\n",
    "  with open('images.json', 'w') as fp:\n",
    "    json.dump(imagedict, fp)\n",
    "\n",
    "mk_image_class_dict(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tuples(dict_classes, bucket, mode):\n",
    "    image_tuples = []\n",
    "    if mode == \"train\":\n",
    "        copies = 200\n",
    "    elif mode == \"test\":\n",
    "        copies = 20\n",
    "    \n",
    "    for key in dict_classes.keys():\n",
    "        if \"not_sources\" in key and mode not in key:\n",
    "            continue\n",
    "        sample_object = bucket.object(key)\n",
    "        sample_data = sample_object.download()\n",
    "        stream = io.BytesIO(sample_data)\n",
    "        my_image = Image.open(stream)\n",
    "        image_matrix = np.asarray(my_image)\n",
    "        if len(image_matrix.shape) < 3 or image_matrix.shape[2] != 3:\n",
    "            print(image_matrix.shape)\n",
    "            continue\n",
    "        for i in range(copies):\n",
    "            input_image = misc.imresize(generate_cut(image_matrix), (40, 60))\n",
    "            image_tuples.append((input_image, dict_classes[key]))\n",
    "    return image_tuples\n",
    "\n",
    "image_tuples_test = create_tuples(my_dict, sample_bucket, \"test\")\n",
    "image_tuples_train = create_tuples(my_dict, sample_bucket, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tuples_test[23][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 100\n",
    "def create_input(images, num_batches, mode):\n",
    "    ran_image_tuples = [(a.ravel()/255, np.asarray(b, dtype=\"float32\")) for a,b in images]\n",
    "    ran_image_lists = list(map(list, zip(*ran_image_tuples)))\n",
    "    if mode == \"train\":\n",
    "        input_batches_list = np.array_split(np.vstack(ran_image_lists[0]), num_batches)\n",
    "        label_batches_list = np.array_split(np.vstack(ran_image_lists[1]), num_batches)\n",
    "    elif mode == \"test\":\n",
    "        input_batches_list = np.vstack(ran_image_lists[0])\n",
    "        label_batches_list = np.vstack(ran_image_lists[1])\n",
    "    else:\n",
    "        print(\"te estas inventando el modo o se te ha olvidado\")\n",
    "        return\n",
    "    return input_batches_list, label_batches_list\n",
    "\n",
    "random.shuffle(image_tuples_train)\n",
    "random.shuffle(image_tuples_test)\n",
    "X_train, Y_train = create_input(image_tuples_train, num_batches, mode=\"train\")\n",
    "X_test, Y_test = create_input(image_tuples_test, num_batches, mode=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_train[0]), X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear model with AdamOptimizer\n",
    "\n",
    "x_im = 60\n",
    "y_im = 40\n",
    "pixel_im = 3\n",
    "output_dim = len(my_dict[\"sources/images.jpg\"])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, x_im*y_im*pixel_im], name=\"input\")\n",
    "W = tf.Variable(tf.zeros([x_im*y_im*pixel_im, output_dim]))\n",
    "b = tf.Variable(tf.zeros([output_dim]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b, name=\"output\")\n",
    "\n",
    "y_actual = tf.placeholder(tf.float32, [None, output_dim])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "              tf.nn.softmax_cross_entropy_with_logits(labels=y_actual, logits=y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "sess1 = tf.InteractiveSession()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for j in range(40):\n",
    "    for i in range(num_batches):\n",
    "        batch_xs, batch_ys = X_train[i], Y_train[i]\n",
    "        sess1.run(train_step, feed_dict={x: batch_xs, y_actual: batch_ys})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_actual,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(sess1.run(accuracy, feed_dict={x: X_test, y_actual: Y_test}))\n",
    "#print(sess1.run(y, feed_dict={x: X_test, y_actual: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gsutil rm gs://copyright/models/linear_model/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saver = tf.train.Saver()\n",
    "#Saver.save(sess1, \"linear_model\")\n",
    "Saver.save(sess1, \"gs://copyright/models/linear_model/linear_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional network\n",
    "\n",
    "x_im = 60\n",
    "y_im = 40\n",
    "pixel_im = 3\n",
    "output_dim = len(my_dict[\"sources/images.jpg\"])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, x_im*y_im*pixel_im], name=\"input\")\n",
    "y_actual = tf.placeholder(tf.float32, [None, output_dim])\n",
    "x_image = tf.reshape(x, [-1, x_im, y_im, pixel_im])\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, pixel_im, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([15 * 10 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 15*10*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "W_fc2 = weight_variable([1024, output_dim])\n",
    "b_fc2 = bias_variable([output_dim])\n",
    "y_conv = tf.add(tf.matmul(h_fc1, W_fc2), b_fc2, name=\"output\")\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_actual, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_actual, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(500):\n",
    "    if i % 100 == 0:\n",
    "        sample_batch = random.randint(0, num_batches - 1)\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                        x: X_train[sample_batch], y_actual: Y_train[sample_batch]})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: X_train[i%num_batches], y_actual: Y_train[i%num_batches]})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "  x: X_test, y_actual: Y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gsutil rm gs://copyright/models/convolutional_network/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saver = tf.train.Saver()\n",
    "#Saver.save(sess, \"convolutional_network\")\n",
    "Saver.save(sess, \"gs://copyright/models/convolutional_network/convolutional_network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "  get_output = tf.argmax(y_conv,1) \n",
    "  _input = np.atleast_2d(X_test[i])\n",
    "  print(sess.run(get_output, feed_dict={x: _input}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.atleast_2d(X_test[1]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
