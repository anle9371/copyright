{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: URL must name a bucket for the defacl command\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil defacl set public-read gs://copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def limit(a, b):\n",
    "    if a < b:\n",
    "        return a\n",
    "    else: return b\n",
    "    \n",
    "def generate_cut(image_matrix):\n",
    "    x,y = image_matrix.shape[:2]\n",
    "    x_start = random.randint(0, int(x/2))\n",
    "    y_start = random.randint(0, int(y/2))\n",
    "    x_end = limit(x_start + int(x/2) + random.randint(0, int(x/16)), x)\n",
    "    y_end = limit(y_start + int(y/2) + random.randint(0, int(y/16)), y)\n",
    "    image_cut = image_matrix[x_start:x_end, y_start:y_end]\n",
    "    return image_cut\n",
    "\n",
    "def one_hot(x, len_ls):\n",
    "    a = np.zeros(len_ls, 'uint8')\n",
    "    a[x] = 1\n",
    "    return a\n",
    "\n",
    "def gen_file_dict(my_files, len_vector):\n",
    "    my_labels = {}\n",
    "    file_num = 0\n",
    "    for file in my_files:\n",
    "        if \"not_sources\" in file:\n",
    "            my_labels[file] = one_hot(len(my_files), len(my_files)+1)\n",
    "        else:\n",
    "            my_labels[file] = one_hot(file_num, len(my_files)+1)\n",
    "            file_num = file_num + 1\n",
    "    return my_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gs://copyright/sources/images.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d34365f54a61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"gs://copyright/sources\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gs://copyright/not_sources/train/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"not_sources/test/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gs://copyright/sources/images.jpg\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# dict_files = {}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# #mode=\"L\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gs://copyright/sources/images.jpg'"
     ]
    }
   ],
   "source": [
    "my_paths = [\"gs://copyright/sources\", \"gs://copyright/not_sources/train/\", \"not_sources/test/\"]\n",
    "f = open(\"gs://copyright/sources/images.jpg\" , 'rb' )\n",
    "# dict_files = {}\n",
    "# #mode=\"L\"\n",
    "\n",
    "# #for path in my_paths:\n",
    "# def get_file_list(path, dict_files):\n",
    "#     my_files_paths = []\n",
    "#     for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "#         my_files_paths.extend([ path + file for file in filenames])\n",
    "#         break\n",
    "#     dict_files[path] = my_files_paths\n",
    "#     return\n",
    "\n",
    "# def get_labels(dict_files):\n",
    "#     labels_dict = {}\n",
    "#     encoding_pos = 0\n",
    "#     for key in dict_files:\n",
    "#         for i in dict_files[key]:\n",
    "#             if \"not_sources\" in i:\n",
    "#                 labels_dict[i] = one_hot(len(dict_files[\"sources/\"]), len(dict_files[\"sources/\"]) + 1)\n",
    "#             else:\n",
    "#                 labels_dict[i] = one_hot(encoding_pos, len(dict_files[\"sources/\"]) + 1)\n",
    "#                 encoding_pos = encoding_pos + 1\n",
    "#     return labels_dict\n",
    "                \n",
    "            \n",
    "    \n",
    "\n",
    "# for path in my_paths:\n",
    "#     get_file_list(path, dict_files)\n",
    "    \n",
    "# labels_dict = get_labels(dict_files)\n",
    "        \n",
    "# labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgarciagonzalez\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\pgarciagonzalez\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289, 300)\n",
      "(217, 300)\n",
      "(240, 300)\n",
      "(300, 300)\n",
      "(300, 300)\n",
      "(300, 300)\n",
      "(278, 300)\n",
      "(167, 300)\n",
      "(164, 300)\n",
      "(245, 300)\n",
      "(300, 298)\n",
      "(282, 300)\n",
      "(300, 265)\n",
      "(295, 300)\n"
     ]
    }
   ],
   "source": [
    "def create_tuples(dict_paths, labels_dict, mode):\n",
    "    image_tuples = []\n",
    "    if mode == \"train\":\n",
    "        copies = 200\n",
    "    elif mode == \"test\":\n",
    "        copies = 20\n",
    "    \n",
    "    for key in dict_paths.keys():\n",
    "        if \"not_sources\" in key and mode not in key:\n",
    "            continue\n",
    "        for path in dict_paths[key]:\n",
    "            image = misc.imread(path)\n",
    "            if len(image.shape) < 3 or image.shape[2] != 3:\n",
    "                print(image.shape)\n",
    "                continue\n",
    "            for i in range(copies):\n",
    "                input_image = misc.imresize(generate_cut(image), (40, 60))\n",
    "                image_tuples.append((input_image, labels_dict[path]))\n",
    "    return image_tuples\n",
    "\n",
    "image_tuples_test = create_tuples(dict_files, labels_dict, \"test\")\n",
    "image_tuples_train = create_tuples(dict_files, labels_dict, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_batches = 100\n",
    "def create_input(images, num_batches, mode):\n",
    "    ran_image_tuples = [(a.ravel()/255, np.asarray(b, dtype=\"float32\")) for a,b in images]\n",
    "    ran_image_lists = list(map(list, zip(*ran_image_tuples)))\n",
    "    if mode == \"train\":\n",
    "        input_batches_list = np.array_split(np.vstack(ran_image_lists[0]), num_batches)\n",
    "        label_batches_list = np.array_split(np.vstack(ran_image_lists[1]), num_batches)\n",
    "    elif mode == \"test\":\n",
    "        input_batches_list = np.vstack(ran_image_lists[0])\n",
    "        label_batches_list = np.vstack(ran_image_lists[1])\n",
    "    else:\n",
    "        print(\"te estas inventando el modo o se te ha olvidado\")\n",
    "        return\n",
    "    return input_batches_list, label_batches_list\n",
    "\n",
    "random.shuffle(image_tuples_train)\n",
    "random.shuffle(image_tuples_test)\n",
    "# threshold = int(len(image_tuples)*0.8)\n",
    "# train_image_tuples = image_tuples[0:threshold]\n",
    "# test_image_tuples = image_tuples[threshold:]\n",
    "X_train, Y_train = create_input(image_tuples_train, num_batches, mode=\"train\")\n",
    "X_test, Y_test = create_input(image_tuples_test, num_batches, mode=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, (250, 7200))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train[0]), X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linear model with AdamOptimizer\n",
    "\n",
    "x_im = 60\n",
    "y_im = 40\n",
    "pixel_im = 3\n",
    "output_dim = len(dict_files[\"sources/\"])+1\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, x_im*y_im*pixel_im])\n",
    "W = tf.Variable(tf.zeros([x_im*y_im*pixel_im, output_dim]))\n",
    "b = tf.Variable(tf.zeros([output_dim]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "y_actual = tf.placeholder(tf.float32, [None, output_dim])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "              tf.nn.softmax_cross_entropy_with_logits(labels=y_actual, logits=y))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "sess1 = tf.InteractiveSession()\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for j in range(40):\n",
    "    for i in range(num_batches):\n",
    "        batch_xs, batch_ys = X_train[i], Y_train[i]\n",
    "        sess1.run(train_step, feed_dict={x: batch_xs, y_actual: batch_ys})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.472222\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_actual,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(sess1.run(accuracy, feed_dict={x: X_test, y_actual: Y_test}))\n",
    "#print(sess1.run(y, feed_dict={x: X_test, y_actual: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0\n",
      "step 100, training accuracy 0.368\n",
      "step 200, training accuracy 0.616\n",
      "step 300, training accuracy 0.756\n",
      "step 400, training accuracy 0.86\n",
      "step 500, training accuracy 0.928\n",
      "step 600, training accuracy 0.948\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.968\n",
      "step 900, training accuracy 0.992\n",
      "test accuracy 0.834314\n"
     ]
    }
   ],
   "source": [
    "#convolutional network\n",
    "\n",
    "x_im = 60\n",
    "y_im = 40\n",
    "pixel_im = 3\n",
    "output_dim = len(dict_files[\"sources/\"])+1\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, x_im*y_im*pixel_im])\n",
    "y_actual = tf.placeholder(tf.float32, [None, output_dim])\n",
    "x_image = tf.reshape(x, [-1, x_im, y_im, pixel_im])\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, pixel_im, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([15 * 10 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 15*10*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "W_fc2 = weight_variable([1024, output_dim])\n",
    "b_fc2 = bias_variable([output_dim])\n",
    "y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_actual, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_actual, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    if i % 100 == 0:\n",
    "        sample_batch = random.randint(0, num_batches - 1)\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                        x: X_train[sample_batch], y_actual: Y_train[sample_batch]})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: X_train[i%num_batches], y_actual: Y_train[i%num_batches]})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "  x: X_test, y_actual: Y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgarciagonzalez\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADwAAAAoCAIAAAAt2Q6oAAAThUlEQVR4nF12WY8lSZbWOcfMfLtb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\n3t9/9+3b0/zTQsvBwPrJ9P8DKpsAkCOCh98AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=60x40 at 0x2448CFA8400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get an sample image cut\n",
    "\n",
    "num = 13\n",
    "my_image_cut = X_test[num]\n",
    "misc.toimage((X_test[num]*255).reshape(40, 60, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([81], dtype=int64) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 270\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    271\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2707\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2708\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2796\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[1;32m-> 2797\u001b[1;33m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[0;32m   2798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-194ff4e16eae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_conv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmy_image_cut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_image_cut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmy_image_cut\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1109\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \"\"\"\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    272\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    273\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    275\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument array([81], dtype=int64) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "#input cut image to the model\n",
    "get_output = tf.argmax(y_conv, 1)\n",
    "my_image_cut = my_image_cut.reshape(-1, 7200)\n",
    "print(sess1.run(get_output.eval(feed_dict={x: my_image_cut}, session=sess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print image\n",
    "\n",
    "my_output_path = \"\"\n",
    "one_hot_output = one_hot(output, len(dict_files[\"sources/\"]) + 1)\n",
    "for key,item in dict_files[\"sources/\"].items():\n",
    "    if (item == one_hot_output).all():\n",
    "        my_output_path = key\n",
    "        break\n",
    "        \n",
    "if my_output_path == \"\":\n",
    "    print(\"this cut does not belong to the dataset\")\n",
    "else\n",
    "    my_output_image = misc.imread(image_path)\n",
    "    plt.imshow(misc.toimage(my_output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_image_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgarciagonzalez\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.], dtype=float32),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = 234\n",
    "A = misc.toimage((X_test[pos]*255).reshape(60, 100, 3))\n",
    "A.show(), Y_test[pos], labels[\"image7.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [(a.ravel(), np.asarray(b, dtype=\"float32\")) for a,b in image_tuples]\n",
    "B = list(map(list, zip(*A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0], labels[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1118.,   882.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgarciagonzalez\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAAA8CAIAAAAfXYiZAAAsa0lEQVR4nGW8V5NlWXYetsw2x1yT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\nb8LynktX/wWrplAUjdLDuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x60 at 0x2AF3E210828>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misc.toimage(image_tuples[2567][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a\" in \"bjskalksm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'google.appengine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0b7a5586b8fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m bucket_name = os.environ.get('BUCKET_NAME',\n\u001b[1;32m      4\u001b[0m                              app_identity.get_default_gcs_bucket_name())\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'google.appengine'"
     ]
    }
   ],
   "source": [
    "  from google.appengine.api import app_identity\n",
    "  \n",
    "  bucket_name = os.environ.get('BUCKET_NAME',\n",
    "                               app_identity.get_default_gcs_bucket_name())\n",
    "  print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
